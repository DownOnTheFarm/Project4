{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the preprocessed data into a training and testing dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 1,891\n",
      "Trainable params: 1,891\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_model.add(tf.keras.layers.Dense(units = 30, activation = 'relu' , input_dim = 30)) \n",
    "\n",
    "# Second hidden layer\n",
    "nn_model.add(tf.keras.layers.Dense(units = 30, activation = 'relu' , input_dim = 30)) \n",
    "\n",
    "# Output layer\n",
    "nn_model.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_model.compile(loss = 'binary_crossentropy' , optimizer = 'adam' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 426 samples\n",
      "Epoch 1/50\n",
      "426/426 [==============================] - 0s 42us/sample - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 2/50\n",
      "426/426 [==============================] - 0s 68us/sample - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "426/426 [==============================] - 0s 59us/sample - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "426/426 [==============================] - 0s 44us/sample - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "426/426 [==============================] - 0s 42us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "426/426 [==============================] - 0s 42us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "426/426 [==============================] - 0s 42us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "426/426 [==============================] - 0s 49us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "426/426 [==============================] - 0s 68us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "426/426 [==============================] - 0s 61us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "426/426 [==============================] - 0s 59us/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "426/426 [==============================] - 0s 63us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "426/426 [==============================] - 0s 49us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "426/426 [==============================] - 0s 44us/sample - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "426/426 [==============================] - 0s 51us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "426/426 [==============================] - 0s 40us/sample - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "426/426 [==============================] - 0s 61us/sample - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "426/426 [==============================] - 0s 54us/sample - loss: 9.7699e-04 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "426/426 [==============================] - 0s 63us/sample - loss: 9.2411e-04 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "426/426 [==============================] - 0s 96us/sample - loss: 9.0529e-04 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "426/426 [==============================] - 0s 61us/sample - loss: 8.8754e-04 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 8.6645e-04 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "426/426 [==============================] - 0s 42us/sample - loss: 8.5430e-04 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "426/426 [==============================] - 0s 47us/sample - loss: 8.2504e-04 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 8.0514e-04 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "426/426 [==============================] - 0s 47us/sample - loss: 7.9449e-04 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 7.7643e-04 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "426/426 [==============================] - 0s 63us/sample - loss: 7.7175e-04 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "426/426 [==============================] - 0s 59us/sample - loss: 7.4238e-04 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "426/426 [==============================] - 0s 57us/sample - loss: 7.4290e-04 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "426/426 [==============================] - 0s 63us/sample - loss: 7.2762e-04 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "426/426 [==============================] - 0s 63us/sample - loss: 7.1850e-04 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 7.1470e-04 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "426/426 [==============================] - 0s 52us/sample - loss: 6.7992e-04 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "426/426 [==============================] - 0s 54us/sample - loss: 6.6491e-04 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "426/426 [==============================] - 0s 49us/sample - loss: 6.3537e-04 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 6.2959e-04 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "426/426 [==============================] - 0s 50us/sample - loss: 6.1597e-04 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "426/426 [==============================] - 0s 52us/sample - loss: 6.0884e-04 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "426/426 [==============================] - 0s 52us/sample - loss: 5.8884e-04 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "426/426 [==============================] - 0s 63us/sample - loss: 5.8945e-04 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "426/426 [==============================] - 0s 51us/sample - loss: 5.7364e-04 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "426/426 [==============================] - 0s 61us/sample - loss: 5.6641e-04 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "426/426 [==============================] - 0s 52us/sample - loss: 5.6159e-04 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "426/426 [==============================] - 0s 63us/sample - loss: 5.4509e-04 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 5.3499e-04 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "426/426 [==============================] - 0s 54us/sample - loss: 5.2404e-04 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "426/426 [==============================] - 0s 59us/sample - loss: 5.1634e-04 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 5.0564e-04 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train_scaled , y_train , epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 - 0s - loss: 0.1675 - accuracy: 0.9580\n",
      "Loss: 0.16745750882526064, Accuracy: 0.9580419659614563\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.save(\"breast_cancer1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 50)                1550      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 6,701\n",
      "Trainable params: 6,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "nn_model2 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_model2.add(tf.keras.layers.Dense(units = 50, activation = 'relu' , input_dim = 30)) \n",
    "\n",
    "# Second hidden layer\n",
    "nn_model2.add(tf.keras.layers.Dense(units = 50, activation = 'relu' , input_dim = 30)) \n",
    "\n",
    "# Third hidden layer\n",
    "nn_model2.add(tf.keras.layers.Dense(units = 50, activation = 'relu' , input_dim = 30)) \n",
    "\n",
    "# Output layer\n",
    "nn_model2.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_model2.compile(loss = 'binary_crossentropy' , optimizer = 'adam' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 426 samples\n",
      "Epoch 1/100\n",
      "426/426 [==============================] - 0s 1ms/sample - loss: 0.6309 - accuracy: 0.6033\n",
      "Epoch 2/100\n",
      "426/426 [==============================] - 0s 49us/sample - loss: 0.3457 - accuracy: 0.9366\n",
      "Epoch 3/100\n",
      "426/426 [==============================] - 0s 47us/sample - loss: 0.1888 - accuracy: 0.9484\n",
      "Epoch 4/100\n",
      "426/426 [==============================] - 0s 63us/sample - loss: 0.1126 - accuracy: 0.9601\n",
      "Epoch 5/100\n",
      "426/426 [==============================] - 0s 59us/sample - loss: 0.0825 - accuracy: 0.9648\n",
      "Epoch 6/100\n",
      "426/426 [==============================] - 0s 59us/sample - loss: 0.0654 - accuracy: 0.9812\n",
      "Epoch 7/100\n",
      "426/426 [==============================] - 0s 59us/sample - loss: 0.0560 - accuracy: 0.9883\n",
      "Epoch 8/100\n",
      "426/426 [==============================] - 0s 66us/sample - loss: 0.0493 - accuracy: 0.9906\n",
      "Epoch 9/100\n",
      "426/426 [==============================] - 0s 70us/sample - loss: 0.0419 - accuracy: 0.9930\n",
      "Epoch 10/100\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0383 - accuracy: 0.9906\n",
      "Epoch 11/100\n",
      "426/426 [==============================] - 0s 66us/sample - loss: 0.0342 - accuracy: 0.9906\n",
      "Epoch 12/100\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0299 - accuracy: 0.9906\n",
      "Epoch 13/100\n",
      "426/426 [==============================] - 0s 80us/sample - loss: 0.0253 - accuracy: 0.9930\n",
      "Epoch 14/100\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0230 - accuracy: 0.9930\n",
      "Epoch 15/100\n",
      "426/426 [==============================] - 0s 66us/sample - loss: 0.0202 - accuracy: 0.9930\n",
      "Epoch 16/100\n",
      "426/426 [==============================] - 0s 68us/sample - loss: 0.0178 - accuracy: 0.9953\n",
      "Epoch 17/100\n",
      "426/426 [==============================] - 0s 54us/sample - loss: 0.0157 - accuracy: 0.9953\n",
      "Epoch 18/100\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0130 - accuracy: 0.9977\n",
      "Epoch 19/100\n",
      "426/426 [==============================] - 0s 69us/sample - loss: 0.0111 - accuracy: 0.9977\n",
      "Epoch 20/100\n",
      "426/426 [==============================] - 0s 49us/sample - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "426/426 [==============================] - 0s 79us/sample - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "426/426 [==============================] - 0s 66us/sample - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "426/426 [==============================] - 0s 42us/sample - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "426/426 [==============================] - 0s 63us/sample - loss: 0.0038 - accuracy: 0.9977\n",
      "Epoch 30/100\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "426/426 [==============================] - 0s 59us/sample - loss: 0.0058 - accuracy: 0.9953\n",
      "Epoch 32/100\n",
      "426/426 [==============================] - 0s 54us/sample - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "426/426 [==============================] - 0s 80us/sample - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "426/426 [==============================] - 0s 63us/sample - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "426/426 [==============================] - 0s 44us/sample - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "426/426 [==============================] - 0s 44us/sample - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "426/426 [==============================] - 0s 49us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "426/426 [==============================] - 0s 47us/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "426/426 [==============================] - 0s 59us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "426/426 [==============================] - 0s 49us/sample - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "426/426 [==============================] - 0s 66us/sample - loss: 9.5204e-04 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "426/426 [==============================] - 0s 54us/sample - loss: 8.1762e-04 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "426/426 [==============================] - 0s 66us/sample - loss: 9.1485e-04 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 7.4275e-04 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "426/426 [==============================] - 0s 59us/sample - loss: 7.5212e-04 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 7.1054e-04 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 6.7191e-04 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "426/426 [==============================] - 0s 52us/sample - loss: 6.0734e-04 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 5.8836e-04 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 5.5496e-04 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 5.3099e-04 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "426/426 [==============================] - 0s 82us/sample - loss: 5.0704e-04 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "426/426 [==============================] - 0s 70us/sample - loss: 4.8975e-04 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "426/426 [==============================] - 0s 80us/sample - loss: 5.0434e-04 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 5.2943e-04 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "426/426 [==============================] - 0s 80us/sample - loss: 4.8808e-04 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "426/426 [==============================] - 0s 78us/sample - loss: 3.7664e-04 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "426/426 [==============================] - 0s 96us/sample - loss: 4.2550e-04 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "426/426 [==============================] - 0s 80us/sample - loss: 3.7318e-04 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 3.4738e-04 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "426/426 [==============================] - 0s 70us/sample - loss: 3.4258e-04 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "426/426 [==============================] - 0s 66us/sample - loss: 3.3612e-04 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 3.2316e-04 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "426/426 [==============================] - 0s 66us/sample - loss: 3.0192e-04 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "426/426 [==============================] - 0s 70us/sample - loss: 2.9720e-04 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "426/426 [==============================] - 0s 55us/sample - loss: 2.8641e-04 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "426/426 [==============================] - 0s 59us/sample - loss: 2.6877e-04 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "426/426 [==============================] - 0s 44us/sample - loss: 2.6228e-04 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "426/426 [==============================] - 0s 63us/sample - loss: 2.5181e-04 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "426/426 [==============================] - 0s 63us/sample - loss: 2.4653e-04 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 2.3905e-04 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "426/426 [==============================] - 0s 68us/sample - loss: 2.3346e-04 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "426/426 [==============================] - 0s 61us/sample - loss: 2.2528e-04 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "426/426 [==============================] - 0s 42us/sample - loss: 2.1612e-04 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "426/426 [==============================] - 0s 61us/sample - loss: 2.1437e-04 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "426/426 [==============================] - 0s 68us/sample - loss: 2.0910e-04 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 2.0265e-04 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "426/426 [==============================] - 0s 54us/sample - loss: 1.9632e-04 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "426/426 [==============================] - 0s 70us/sample - loss: 1.9441e-04 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "426/426 [==============================] - 0s 63us/sample - loss: 1.8517e-04 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "426/426 [==============================] - 0s 74us/sample - loss: 1.8153e-04 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "426/426 [==============================] - 0s 54us/sample - loss: 1.7090e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 1.8082e-04 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "426/426 [==============================] - 0s 68us/sample - loss: 1.6568e-04 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "426/426 [==============================] - 0s 47us/sample - loss: 1.5873e-04 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 1.5552e-04 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "426/426 [==============================] - 0s 59us/sample - loss: 1.4713e-04 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "426/426 [==============================] - 0s 70us/sample - loss: 1.4461e-04 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "426/426 [==============================] - 0s 61us/sample - loss: 1.4200e-04 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "426/426 [==============================] - 0s 87us/sample - loss: 1.4005e-04 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "426/426 [==============================] - 0s 66us/sample - loss: 1.3446e-04 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 1.3085e-04 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 1.2834e-04 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 1.2305e-04 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "426/426 [==============================] - 0s 70us/sample - loss: 1.2742e-04 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "426/426 [==============================] - 0s 66us/sample - loss: 1.2434e-04 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "426/426 [==============================] - 0s 54us/sample - loss: 1.2755e-04 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 1.1503e-04 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model2.fit(X_train_scaled , y_train , epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 - 0s - loss: 0.1457 - accuracy: 0.9720\n",
      "Loss: 0.1456772396015329, Accuracy: 0.9720279574394226\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model2.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.save(\"breast_cancer2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 100)               3100      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 23,401\n",
      "Trainable params: 23,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "nn_model3 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_model3.add(tf.keras.layers.Dense(units = 100, activation = 'relu' , input_dim = 30)) \n",
    "\n",
    "# Second hidden layer\n",
    "nn_model3.add(tf.keras.layers.Dense(units = 100, activation = 'relu' , input_dim = 30)) \n",
    "\n",
    "# Third hidden layer\n",
    "nn_model3.add(tf.keras.layers.Dense(units = 100, activation = 'relu' , input_dim = 30)) \n",
    "\n",
    "# Output layer\n",
    "nn_model3.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_model3.compile(loss = 'binary_crossentropy' , optimizer = 'adam' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 426 samples\n",
      "Epoch 1/100\n",
      "426/426 [==============================] - 0s 988us/sample - loss: 0.4865 - accuracy: 0.8005\n",
      "Epoch 2/100\n",
      "426/426 [==============================] - 0s 54us/sample - loss: 0.1586 - accuracy: 0.9554\n",
      "Epoch 3/100\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0906 - accuracy: 0.9648\n",
      "Epoch 4/100\n",
      "426/426 [==============================] - 0s 68us/sample - loss: 0.0627 - accuracy: 0.9812\n",
      "Epoch 5/100\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.0504 - accuracy: 0.9859\n",
      "Epoch 6/100\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0391 - accuracy: 0.9930\n",
      "Epoch 7/100\n",
      "426/426 [==============================] - 0s 82us/sample - loss: 0.0340 - accuracy: 0.9930\n",
      "Epoch 8/100\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0266 - accuracy: 0.9930\n",
      "Epoch 9/100\n",
      "426/426 [==============================] - 0s 63us/sample - loss: 0.0217 - accuracy: 0.9930\n",
      "Epoch 10/100\n",
      "426/426 [==============================] - 0s 61us/sample - loss: 0.0172 - accuracy: 0.9930\n",
      "Epoch 11/100\n",
      "426/426 [==============================] - 0s 66us/sample - loss: 0.0136 - accuracy: 0.9953\n",
      "Epoch 12/100\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0097 - accuracy: 0.9977\n",
      "Epoch 13/100\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "426/426 [==============================] - 0s 80us/sample - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "426/426 [==============================] - 0s 87us/sample - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "426/426 [==============================] - 0s 68us/sample - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "426/426 [==============================] - 0s 59us/sample - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "426/426 [==============================] - 0s 70us/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "426/426 [==============================] - 0s 63us/sample - loss: 8.9998e-04 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 7.9724e-04 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "426/426 [==============================] - 0s 124us/sample - loss: 7.2666e-04 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "426/426 [==============================] - 0s 104us/sample - loss: 6.4872e-04 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 5.9341e-04 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "426/426 [==============================] - 0s 87us/sample - loss: 5.2552e-04 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "426/426 [==============================] - 0s 108us/sample - loss: 5.0314e-04 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "426/426 [==============================] - 0s 110us/sample - loss: 4.4423e-04 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "426/426 [==============================] - 0s 138us/sample - loss: 4.2485e-04 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "426/426 [==============================] - 0s 105us/sample - loss: 3.7368e-04 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "426/426 [==============================] - 0s 110us/sample - loss: 3.4695e-04 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "426/426 [==============================] - 0s 82us/sample - loss: 3.2220e-04 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "426/426 [==============================] - 0s 79us/sample - loss: 2.9977e-04 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "426/426 [==============================] - 0s 82us/sample - loss: 2.8646e-04 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "426/426 [==============================] - 0s 76us/sample - loss: 2.6982e-04 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 2.6006e-04 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 2.3247e-04 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "426/426 [==============================] - 0s 61us/sample - loss: 2.4206e-04 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "426/426 [==============================] - 0s 63us/sample - loss: 2.1041e-04 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 1.9380e-04 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "426/426 [==============================] - 0s 108us/sample - loss: 1.8565e-04 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 1.7592e-04 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "426/426 [==============================] - 0s 63us/sample - loss: 1.6958e-04 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "426/426 [==============================] - 0s 87us/sample - loss: 1.6122e-04 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "426/426 [==============================] - 0s 101us/sample - loss: 1.5108e-04 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 1.4178e-04 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "426/426 [==============================] - 0s 117us/sample - loss: 1.3633e-04 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "426/426 [==============================] - 0s 122us/sample - loss: 1.3015e-04 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 1.2611e-04 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "426/426 [==============================] - 0s 166us/sample - loss: 1.1881e-04 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "426/426 [==============================] - 0s 171us/sample - loss: 1.1734e-04 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "426/426 [==============================] - 0s 80us/sample - loss: 1.1386e-04 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "426/426 [==============================] - 0s 112us/sample - loss: 1.0690e-04 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "426/426 [==============================] - 0s 112us/sample - loss: 1.0129e-04 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 9.6269e-05 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "426/426 [==============================] - 0s 68us/sample - loss: 9.2825e-05 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "426/426 [==============================] - 0s 70us/sample - loss: 8.8807e-05 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "426/426 [==============================] - 0s 52us/sample - loss: 8.6325e-05 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "426/426 [==============================] - 0s 37us/sample - loss: 8.3988e-05 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "426/426 [==============================] - 0s 42us/sample - loss: 8.0565e-05 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "426/426 [==============================] - 0s 63us/sample - loss: 7.6953e-05 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "426/426 [==============================] - 0s 59us/sample - loss: 7.4281e-05 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "426/426 [==============================] - 0s 59us/sample - loss: 7.1800e-05 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "426/426 [==============================] - 0s 70us/sample - loss: 6.9397e-05 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "426/426 [==============================] - 0s 49us/sample - loss: 6.6495e-05 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "426/426 [==============================] - 0s 47us/sample - loss: 6.4594e-05 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "426/426 [==============================] - 0s 44us/sample - loss: 6.2371e-05 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "426/426 [==============================] - 0s 44us/sample - loss: 6.0467e-05 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "426/426 [==============================] - 0s 40us/sample - loss: 5.8313e-05 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "426/426 [==============================] - 0s 68us/sample - loss: 5.7134e-05 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 5.5107e-05 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "426/426 [==============================] - 0s 70us/sample - loss: 5.3320e-05 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 5.2068e-05 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "426/426 [==============================] - 0s 52us/sample - loss: 5.0145e-05 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 4.9208e-05 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "426/426 [==============================] - 0s 52us/sample - loss: 4.7451e-05 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 4.6607e-05 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 4.4714e-05 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "426/426 [==============================] - 0s 122us/sample - loss: 4.3510e-05 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "426/426 [==============================] - 0s 107us/sample - loss: 4.2506e-05 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 4.1204e-05 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "426/426 [==============================] - 0s 119us/sample - loss: 3.9839e-05 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "426/426 [==============================] - 0s 82us/sample - loss: 3.9167e-05 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "426/426 [==============================] - 0s 59us/sample - loss: 3.8057e-05 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "426/426 [==============================] - 0s 68us/sample - loss: 3.6966e-05 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 3.6625e-05 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 3.4782e-05 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 3.4300e-05 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "426/426 [==============================] - 0s 87us/sample - loss: 3.3130e-05 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "426/426 [==============================] - 0s 61us/sample - loss: 3.2131e-05 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "426/426 [==============================] - 0s 68us/sample - loss: 3.1571e-05 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 3.0544e-05 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 3.0114e-05 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "426/426 [==============================] - 0s 68us/sample - loss: 2.9110e-05 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 2.8559e-05 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "426/426 [==============================] - 0s 61us/sample - loss: 2.7749e-05 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model3.fit(X_train_scaled , y_train , epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 - 0s - loss: 0.1589 - accuracy: 0.9650\n",
      "Loss: 0.15885426899112134, Accuracy: 0.9650349617004395\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model3.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.save(\"breast_cancer3.h5\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "interpreter": {
   "hash": "352eb0fdbc39df23c3941759226aac7a80e9e8fcb0968112f6f9929c3d7daf2e"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('PythonData': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
